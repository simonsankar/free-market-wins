---
dg-publish: true
---
Utilitarianism is **a theory of morality that advocates actions that foster happiness and oppose actions that cause unhappiness**. Utilitarianism promotes "the greatest amount of good for the greatest number of people."

It's aim is to maximize the 'utility' when deciding what actions to take given a conflict.

This fails on two grounds
- Fundamentally, attempts to convert ordinal data (people's) to cardinal (ratio level data) — [[The Error of Utilitarianism]]
- It permits aggression — [[Mixed Law]]
- 